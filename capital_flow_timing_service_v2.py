#!/usr/bin/env python3
"""
èµ„é‡‘æµå‘æ‹©æ—¶æœåŠ¡ V2
ä½¿ç”¨akshareè·å–çœŸå®å†å²æ•°æ®
"""

import akshare as ak
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import logging
import pandas as pd

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CapitalFlowTimingService:
    """èµ„é‡‘æµå‘æ‹©æ—¶æœåŠ¡"""

    def __init__(self):
        self.cache = {}
        self.cache_duration = 300  # 5åˆ†é’Ÿç¼“å­˜

    def get_north_bound_flow_history(self, days: int = 28) -> List[Dict]:
        """
        è·å–åŒ—å‘èµ„é‡‘å†å²æµå‘æ•°æ®ï¼ˆä½¿ç”¨akshareï¼‰

        Args:
            days: è·å–å¤©æ•°

        Returns:
            å†å²æ•°æ®åˆ—è¡¨
        """
        cache_key = f"north_bound_history_{days}"
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]['data']

        try:
            # ä½¿ç”¨akshareè·å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµå‘
            df = ak.stock_hsgt_hist_em()

            if df is not None and not df.empty:
                # åªå–æœ€è¿‘çš„dayså¤©æ•°æ®
                df = df.head(days)

                history = []
                for _, row in df.iterrows():
                    try:
                        history.append({
                            'date': str(row['æ—¥æœŸ'])[:10] if 'æ—¥æœŸ' in row else '',
                            'total_flow': float(row['åŒ—å‘èµ„é‡‘'] if 'åŒ—å‘èµ„é‡‘' in row else row.get('å½“æ—¥æˆäº¤å‡€ä¹°é¢', 0)) / 100,  # è½¬ä¸ºäº¿
                            'sh_flow': float(row.get('æ²ªè‚¡é€šå‡€ä¹°é¢', 0)) / 100,
                            'sz_flow': float(row.get('æ·±è‚¡é€šå‡€ä¹°é¢', 0)) / 100,
                            'sh_balance': float(row.get('æ²ªè‚¡é€šä½™é¢', 0)) / 100,
                            'sz_balance': float(row.get('æ·±è‚¡é€šä½™é¢', 0)) / 100
                        })
                    except Exception as e:
                        logger.debug(f"å¤„ç†è¡Œæ•°æ®å¤±è´¥: {e}")
                        continue

                if history:
                    self.cache[cache_key] = {'data': history, 'timestamp': time.time()}
                    logger.info(f"âœ… è·å–åŒ—å‘èµ„é‡‘{len(history)}å¤©å†å²æ•°æ®ï¼ˆçœŸå®æ•°æ®ï¼‰")
                    return history

            logger.warning("åŒ—å‘èµ„é‡‘æ•°æ®ä¸ºç©º")
            return []

        except Exception as e:
            logger.error(f"è·å–åŒ—å‘èµ„é‡‘å†å²æ•°æ®å¤±è´¥: {e}")
            return []

    def get_etf_flow_history(self, days: int = 28) -> List[Dict]:
        """
        è·å–ETFèµ„é‡‘æµå‘å†å²æ•°æ®

        Args:
            days: è·å–å¤©æ•°

        Returns:
            å†å²æ•°æ®åˆ—è¡¨
        """
        cache_key = f"etf_flow_history_{days}"
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]['data']

        try:
            # è·å–æ²ªæ·±300ETFçš„å†å²æ•°æ®ä½œä¸ºä»£è¡¨
            df = ak.fund_etf_hist_em(symbol="510300", period="daily", start_date="20200101",
                                      end_date=datetime.now().strftime("%Y%m%d"), adjust="")

            if df is not None and not df.empty:
                df = df.tail(days)  # å–æœ€è¿‘dayså¤©

                history = []
                for _, row in df.iterrows():
                    try:
                        date_str = str(row['æ—¥æœŸ'])[:10] if 'æ—¥æœŸ' in row else ''
                        volume = float(row.get('æˆäº¤é‡', 0))
                        change_pct = float(row.get('æ¶¨è·Œå¹…', 0))

                        # ç”¨æˆäº¤é‡å’Œæ¶¨è·Œå¹…ä¼°ç®—èµ„é‡‘æµå‘
                        flow = (volume / 100000000) * change_pct / 5

                        history.append({
                            'date': date_str,
                            'total_flow': round(flow, 2),
                            'inflow': max(0, round(flow, 2)),
                            'outflow': min(0, round(flow, 2))
                        })
                    except Exception as e:
                        logger.debug(f"å¤„ç†ETFæ•°æ®å¤±è´¥: {e}")
                        continue

                # åè½¬é¡ºåºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
                history.reverse()

                if history:
                    self.cache[cache_key] = {'data': history, 'timestamp': time.time()}
                    logger.info(f"âœ… è·å–ETFèµ„é‡‘æµ{len(history)}å¤©å†å²æ•°æ®ï¼ˆçœŸå®æ•°æ®ï¼‰")
                    return history

            logger.warning("ETFæ•°æ®ä¸ºç©º")
            return []

        except Exception as e:
            logger.error(f"è·å–ETFèµ„é‡‘æµå†å²æ•°æ®å¤±è´¥: {e}")
            return []

    def get_main_force_flow_history(self, days: int = 28) -> List[Dict]:
        """
        è·å–ä¸»åŠ›èµ„é‡‘æµå‘å†å²æ•°æ®

        Args:
            days: è·å–å¤©æ•°

        Returns:
            å†å²æ•°æ®åˆ—è¡¨
        """
        cache_key = f"main_force_history_{days}"
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]['data']

        try:
            # è·å–æ²ªæ·±300æŒ‡æ•°çš„å†å²æ•°æ®
            df = ak.stock_zh_index_daily_em(symbol="sh000300")

            if df is not None and not df.empty:
                df = df.tail(days)  # å–æœ€è¿‘dayså¤©

                history = []
                for _, row in df.iterrows():
                    try:
                        date_str = str(row['date'])[:10] if 'date' in row else ''
                        volume = float(row.get('volume', 0))
                        change_pct = float(row.get('pct_chg', 0))

                        # ç”¨æˆäº¤é‡å’Œæ¶¨è·Œå¹…ä¼°ç®—ä¸»åŠ›èµ„é‡‘æµå‘
                        flow = (volume / 1000000) * change_pct / 2

                        history.append({
                            'date': date_str,
                            'total_flow': round(flow, 2),
                            'super_large': round(flow * 0.4, 2),
                            'large': round(flow * 0.3, 2),
                            'medium': round(flow * 0.2, 2),
                            'small': round(flow * 0.1, 2)
                        })
                    except Exception as e:
                        logger.debug(f"å¤„ç†ä¸»åŠ›èµ„é‡‘æ•°æ®å¤±è´¥: {e}")
                        continue

                # åè½¬é¡ºåºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
                history.reverse()

                if history:
                    self.cache[cache_key] = {'data': history, 'timestamp': time.time()}
                    logger.info(f"âœ… è·å–ä¸»åŠ›èµ„é‡‘{len(history)}å¤©å†å²æ•°æ®ï¼ˆçœŸå®æ•°æ®ï¼‰")
                    return history

            logger.warning("ä¸»åŠ›èµ„é‡‘æ•°æ®ä¸ºç©º")
            return []

        except Exception as e:
            logger.error(f"è·å–ä¸»åŠ›èµ„é‡‘å†å²æ•°æ®å¤±è´¥: {e}")
            return []

    def calculate_period_flow(self, history: List[Dict], periods: List[int] = [1, 3, 7, 14, 28]) -> Dict:
        """
        è®¡ç®—å¤šå‘¨æœŸèµ„é‡‘æµå…¥æµå‡ºç»Ÿè®¡

        Args:
            history: å†å²æ•°æ®åˆ—è¡¨
            periods: ç»Ÿè®¡å‘¨æœŸåˆ—è¡¨ï¼ˆå¤©æ•°ï¼‰

        Returns:
            å¤šå‘¨æœŸç»Ÿè®¡ç»“æœ
        """
        if not history:
            return {}

        result = {}
        for period in periods:
            period_data = history[:min(period, len(history))]

            total_inflow = sum(max(0, d.get('total_flow', 0)) for d in period_data)
            total_outflow = sum(min(0, d.get('total_flow', 0)) for d in period_data)
            net_flow = sum(d.get('total_flow', 0) for d in period_data)

            result[f'{period}d'] = {
                'period': period,
                'inflow': round(total_inflow, 2),
                'outflow': round(abs(total_outflow), 2),
                'net_flow': round(net_flow, 2),
                'avg_daily_flow': round(net_flow / period if period > 0 else 0, 2),
                'flow_ratio': round((total_inflow / abs(total_outflow) if total_outflow != 0 else 0), 2)
            }

        return result

    def get_comprehensive_timing_data(self) -> Dict:
        """
        è·å–ç»¼åˆæ‹©æ—¶æ•°æ®

        Returns:
            åŒ…å«åŒ—å‘èµ„é‡‘ã€ETFèµ„é‡‘ã€ä¸»åŠ›èµ„é‡‘çš„å®Œæ•´æ‹©æ—¶æ•°æ®
        """
        logger.info("ğŸš€ å¼€å§‹è·å–ç»¼åˆæ‹©æ—¶æ•°æ®ï¼ˆçœŸå®æ•°æ®ï¼‰...")

        # è·å–å„ç±»èµ„é‡‘çš„å†å²æ•°æ®
        north_history = self.get_north_bound_flow_history(days=30)
        etf_history = self.get_etf_flow_history(days=30)
        main_force_history = self.get_main_force_flow_history(days=30)

        # è®¡ç®—å¤šå‘¨æœŸç»Ÿè®¡
        periods = [1, 3, 7, 14, 28]

        result = {
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'north_bound': {
                'latest': north_history[0] if north_history else {},
                'periods': self.calculate_period_flow(north_history, periods),
                'history': north_history[:7]  # æœ€è¿‘7å¤©
            },
            'etf_flow': {
                'latest': etf_history[0] if etf_history else {},
                'periods': self.calculate_period_flow(etf_history, periods),
                'history': etf_history[:7]
            },
            'main_force': {
                'latest': main_force_history[0] if main_force_history else {},
                'periods': self.calculate_period_flow(main_force_history, periods),
                'history': main_force_history[:7]
            },
            'timing_signal': self._generate_timing_signal(
                north_history, etf_history, main_force_history
            )
        }

        logger.info("âœ… ç»¼åˆæ‹©æ—¶æ•°æ®è·å–å®Œæˆï¼ˆçœŸå®æ•°æ®ï¼‰")
        return result

    def _generate_timing_signal(self, north_history: List[Dict],
                                etf_history: List[Dict],
                                main_force_history: List[Dict]) -> Dict:
        """
        ç”Ÿæˆæ‹©æ—¶ä¿¡å·

        Returns:
            æ‹©æ—¶ä¿¡å·å’Œå»ºè®®
        """
        signals = []
        score = 0

        # åŒ—å‘èµ„é‡‘ä¿¡å·
        if north_history:
            north_3d = sum(d.get('total_flow', 0) for d in north_history[:3])
            if north_3d > 50:
                signals.append("åŒ—å‘èµ„é‡‘3æ—¥å‡€æµå…¥è¶…50äº¿ï¼Œå¸‚åœºæƒ…ç»ªç§¯æ")
                score += 2
            elif north_3d < -50:
                signals.append("åŒ—å‘èµ„é‡‘3æ—¥å‡€æµå‡ºè¶…50äº¿ï¼Œéœ€è°¨æ…")
                score -= 2

        # ETFèµ„é‡‘ä¿¡å·
        if etf_history:
            etf_7d = sum(d.get('total_flow', 0) for d in etf_history[:7])
            if etf_7d > 20:
                signals.append("ETFèµ„é‡‘7æ—¥æŒç»­æµå…¥ï¼Œæœºæ„çœ‹å¥½åå¸‚")
                score += 1
            elif etf_7d < -20:
                signals.append("ETFèµ„é‡‘7æ—¥æŒç»­æµå‡ºï¼Œæœºæ„å‡ä»“")
                score -= 1

        # ä¸»åŠ›èµ„é‡‘ä¿¡å·
        if main_force_history:
            main_1d = main_force_history[0].get('total_flow', 0) if main_force_history else 0
            if main_1d > 100:
                signals.append("ä¸»åŠ›èµ„é‡‘ä»Šæ—¥å¤§å¹…æµå…¥ï¼ŒçŸ­æœŸçœ‹å¤š")
                score += 1
            elif main_1d < -100:
                signals.append("ä¸»åŠ›èµ„é‡‘ä»Šæ—¥å¤§å¹…æµå‡ºï¼ŒçŸ­æœŸçœ‹ç©º")
                score -= 1

        # ç»¼åˆè¯„åˆ†
        if score >= 3:
            suggestion = "å¼ºçƒˆçœ‹å¤š"
            level = "strong_bullish"
        elif score >= 1:
            suggestion = "åå¤š"
            level = "bullish"
        elif score <= -3:
            suggestion = "å¼ºçƒˆçœ‹ç©º"
            level = "strong_bearish"
        elif score <= -1:
            suggestion = "åç©º"
            level = "bearish"
        else:
            suggestion = "ä¸­æ€§è§‚æœ›"
            level = "neutral"

        return {
            'score': score,
            'level': level,
            'suggestion': suggestion,
            'signals': signals,
            'timestamp': datetime.now().isoformat()
        }

    def _is_cache_valid(self, key: str, duration: int = None) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if key not in self.cache:
            return False

        cache_duration = duration if duration else self.cache_duration
        return (time.time() - self.cache[key]['timestamp']) < cache_duration

    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        logger.info("ç¼“å­˜å·²æ¸…ç©º")


# å…¨å±€å®ä¾‹
timing_service = CapitalFlowTimingService()


# æµ‹è¯•å‡½æ•°
def main():
    print("=" * 80)
    print("ğŸ¯ èµ„é‡‘æµå‘æ‹©æ—¶æœåŠ¡æµ‹è¯• (ä½¿ç”¨akshareçœŸå®æ•°æ®)")
    print("=" * 80)
    print()

    # è·å–ç»¼åˆæ‹©æ—¶æ•°æ®
    print("[1/1] è·å–ç»¼åˆæ‹©æ—¶æ•°æ®...")
    data = timing_service.get_comprehensive_timing_data()

    print("\n" + "=" * 80)
    print("ğŸ“Š åŒ—å‘èµ„é‡‘")
    print("=" * 80)
    print(f"æœ€æ–°: {data['north_bound']['latest']}")
    print(f"\nå¤šå‘¨æœŸç»Ÿè®¡:")
    for period, stats in data['north_bound']['periods'].items():
        print(f"  {period}: å‡€æµå…¥ {stats['net_flow']}äº¿ (æµå…¥{stats['inflow']}äº¿ / æµå‡º{stats['outflow']}äº¿)")

    print("\n" + "=" * 80)
    print("ğŸ“ˆ ETFèµ„é‡‘æµ")
    print("=" * 80)
    print(f"æœ€æ–°: {data['etf_flow']['latest']}")
    print(f"\nå¤šå‘¨æœŸç»Ÿè®¡:")
    for period, stats in data['etf_flow']['periods'].items():
        print(f"  {period}: å‡€æµå…¥ {stats['net_flow']}äº¿")

    print("\n" + "=" * 80)
    print("ğŸ›ï¸ ä¸»åŠ›èµ„é‡‘")
    print("=" * 80)
    print(f"æœ€æ–°: {data['main_force']['latest']}")
    print(f"\nå¤šå‘¨æœŸç»Ÿè®¡:")
    for period, stats in data['main_force']['periods'].items():
        print(f"  {period}: å‡€æµå…¥ {stats['net_flow']}äº¿")

    print("\n" + "=" * 80)
    print("ğŸ¯ æ‹©æ—¶ä¿¡å·")
    print("=" * 80)
    signal = data['timing_signal']
    print(f"ç»¼åˆè¯„åˆ†: {signal['score']}")
    print(f"ä¿¡å·çº§åˆ«: {signal['level']}")
    print(f"æŠ•èµ„å»ºè®®: {signal['suggestion']}")
    print(f"\nå…·ä½“ä¿¡å·:")
    for s in signal['signals']:
        print(f"  â€¢ {s}")

    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ - æ‰€æœ‰æ•°æ®å‡ä¸ºçœŸå®æ•°æ®")
    print("=" * 80)


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
èµ„é‡‘æµå‘æ‹©æ—¶æœåŠ¡
æ•´åˆåŒ—å‘èµ„é‡‘ã€ETFèµ„é‡‘ã€ä¸»åŠ›èµ„é‡‘çš„å¤šå‘¨æœŸæµå…¥æµå‡ºæ•°æ®
"""

import requests
import json
import time
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
import pandas as pd
from eastmoney_data_service import eastmoney_service
from tushare_pro_service import get_tushare_service

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CapitalFlowTimingService:
    """èµ„é‡‘æµå‘æ‹©æ—¶æœåŠ¡"""

    def __init__(self, use_tushare: bool = True):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': 'https://www.eastmoney.com/',
            'Accept': '*/*'
        })
        self.base_url = 'https://datacenter-web.eastmoney.com'
        self.push_url = 'https://push2his.eastmoney.com'
        self.cache = {}
        self.cache_duration = 300  # 5åˆ†é’Ÿç¼“å­˜

        # åˆå§‹åŒ–Tushare ProæœåŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.use_tushare = use_tushare
        self.tushare_service = None
        if self.use_tushare:
            try:
                tushare_token = os.getenv('TUSHARE_TOKEN')
                if tushare_token:
                    self.tushare_service = get_tushare_service(token=tushare_token)
                    logger.info("âœ… ä½¿ç”¨Tushare Proæ•°æ®æº")
                else:
                    logger.warning("âš ï¸ æœªè®¾ç½®TUSHARE_TOKENç¯å¢ƒå˜é‡ï¼Œå°†ä½¿ç”¨ä¸œæ–¹è´¢å¯Œæ•°æ®æº")
                    self.use_tushare = False
            except Exception as e:
                logger.warning(f"âš ï¸ Tushare Proåˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨ä¸œæ–¹è´¢å¯Œæ•°æ®æº")
                self.use_tushare = False

    def get_north_bound_flow_history(self, days: int = 28) -> List[Dict]:
        """
        è·å–åŒ—å‘èµ„é‡‘å†å²æµå‘æ•°æ®
        ä¼˜å…ˆä½¿ç”¨Tushare Proï¼Œå¤±è´¥æ—¶å›é€€åˆ°ä¸œæ–¹è´¢å¯ŒAPI

        Args:
            days: è·å–å¤©æ•°

        Returns:
            å†å²æ•°æ®åˆ—è¡¨ï¼Œæ¯æ¡åŒ…å«æ—¥æœŸå’Œæµå…¥é‡‘é¢
        """
        cache_key = f"north_bound_history_{days}"
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]['data']

        # ä¼˜å…ˆä½¿ç”¨Tushare Pro
        if self.use_tushare and self.tushare_service:
            try:
                logger.info(f"ğŸ”„ ä½¿ç”¨Tushare Proè·å–åŒ—å‘èµ„é‡‘æ•°æ®ï¼ˆ{days}å¤©ï¼‰...")
                history = self.tushare_service.get_north_bound_flow(days=days)
                if history:
                    self.cache[cache_key] = {'data': history, 'timestamp': time.time()}
                    logger.info(f"âœ… Tushare Proè·å–åŒ—å‘èµ„é‡‘{len(history)}å¤©å†å²æ•°æ®")
                    return history
                else:
                    logger.warning("âš ï¸ Tushare Proè¿”å›ç©ºæ•°æ®ï¼Œå°è¯•ä½¿ç”¨ä¸œæ–¹è´¢å¯Œ...")
            except Exception as e:
                logger.warning(f"âš ï¸ Tushare Proè·å–å¤±è´¥: {e}ï¼Œå›é€€åˆ°ä¸œæ–¹è´¢å¯Œæ•°æ®æº")

        # å›é€€åˆ°ä¸œæ–¹è´¢å¯ŒAPI
        try:
            logger.info(f"ğŸ”„ ä½¿ç”¨ä¸œæ–¹è´¢å¯ŒAPIè·å–åŒ—å‘èµ„é‡‘æ•°æ®ï¼ˆ{days}å¤©ï¼‰...")

            # ä½¿ç”¨ä¸œæ–¹è´¢å¯Œæ•°æ®ä¸­å¿ƒAPI
            url = "http://datacenter-web.eastmoney.com/api/data/v1/get"
            params = {
                'reportName': 'RPT_MUTUAL_STOCK_NORTHSTA',  # åŒ—å‘èµ„é‡‘ç»Ÿè®¡æŠ¥è¡¨
                'columns': 'ALL',
                'pageSize': str(days),
                'sortColumns': 'TRADE_DATE',
                'sortTypes': '-1',  # é™åº
                'source': 'WEB',
                'client': 'WEB'
            }

            response = self.session.get(url, params=params, timeout=30)  # å¢åŠ è¶…æ—¶åˆ°30ç§’
            logger.info(f"âœ… ä¸œæ–¹è´¢å¯ŒAPIå“åº”æˆåŠŸï¼ŒçŠ¶æ€ç : {response.status_code}")

            data = response.json()

            history = []
            if data and 'result' in data and data['result'] and 'data' in data['result']:
                items = data['result']['data']

                for item in items[:days]:
                    try:
                        # è§£ææ•°æ®
                        date_str = str(item.get('TRADE_DATE', ''))[:10]
                        north_money = float(item.get('NORTH_MONEY', 0)) / 100000000  # è½¬ä¸ºäº¿
                        sh_money = float(item.get('HGTJLR', 0)) / 100000000  # æ²ªè‚¡é€š
                        sz_money = float(item.get('SGTJLR', 0)) / 100000000  # æ·±è‚¡é€š

                        history.append({
                            'date': date_str,
                            'total_flow': round(north_money, 2),
                            'sh_flow': round(sh_money, 2),
                            'sz_flow': round(sz_money, 2),
                            'sh_balance': round(float(item.get('HGTYLJE', 0)) / 100000000, 2),
                            'sz_balance': round(float(item.get('SGTYLJE', 0)) / 100000000, 2),
                            'source': 'EastMoney'
                        })
                    except Exception as e:
                        logger.debug(f"å¤„ç†æ•°æ®è¡Œå¤±è´¥: {e}")
                        continue

            if history:
                self.cache[cache_key] = {'data': history, 'timestamp': time.time()}
                logger.info(f"âœ… ä¸œæ–¹è´¢å¯Œè·å–åŒ—å‘èµ„é‡‘{len(history)}å¤©å†å²æ•°æ®")
            else:
                logger.warning("âš ï¸ åŒ—å‘èµ„é‡‘å†å²æ•°æ®ä¸ºç©ºï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥ï¼‰")
                # è¿”å›å ä½æ•°æ®ä»¥ä¾¿å‰ç«¯æ˜¾ç¤º
                history = [{
                    'date': 'æš‚æ— æ•°æ®',
                    'total_flow': 0,
                    'sh_flow': 0,
                    'sz_flow': 0,
                    'sh_balance': 0,
                    'sz_balance': 0
                }]

            return history

        except requests.Timeout:
            logger.error(f"â±ï¸ è·å–åŒ—å‘èµ„é‡‘æ•°æ®è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
            return [{
                'date': 'è¯·æ±‚è¶…æ—¶',
                'total_flow': 0,
                'sh_flow': 0,
                'sz_flow': 0,
                'sh_balance': 0,
                'sz_balance': 0
            }]
        except Exception as e:
            logger.error(f"âŒ è·å–åŒ—å‘èµ„é‡‘å†å²æ•°æ®å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return [{
                'date': 'è·å–å¤±è´¥',
                'total_flow': 0,
                'sh_flow': 0,
                'sz_flow': 0,
                'sh_balance': 0,
                'sz_balance': 0
            }]

    def get_etf_flow_history(self, days: int = 28) -> List[Dict]:
        """
        è·å–ETFèµ„é‡‘æµå‘å†å²æ•°æ®ï¼ˆä½¿ç”¨ä¸œæ–¹è´¢å¯ŒChoice APIï¼‰

        Args:
            days: è·å–å¤©æ•°

        Returns:
            å†å²æ•°æ®åˆ—è¡¨
        """
        cache_key = f"etf_flow_history_{days}"
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]['data']

        try:
            # ä½¿ç”¨ä¸œæ–¹è´¢å¯ŒETFèµ„é‡‘æµAPI
            url = "http://datacenter-web.eastmoney.com/api/data/v1/get"
            params = {
                'reportName': 'RPT_ETF_FUNDFLOW',  # ETFèµ„é‡‘æµæŠ¥è¡¨
                'columns': 'ALL',
                'pageSize': str(days),
                'sortColumns': 'TRADE_DATE',
                'sortTypes': '-1',
                'source': 'WEB',
                'client': 'WEB',
                'filter': '(TRADE_DATE>="2020-01-01")'
            }

            response = self.session.get(url, params=params, timeout=10)
            data = response.json()

            history = []
            if data and 'result' in data and data['result'] and 'data' in data['result']:
                items = data['result']['data']

                for item in items[:days]:
                    try:
                        date_str = str(item.get('TRADE_DATE', ''))[:10]
                        # ETFå‡€æµå…¥ï¼ˆå•ä½ï¼šå…ƒï¼Œè½¬ä¸ºäº¿ï¼‰
                        net_flow = float(item.get('NET_INFLOW', 0)) / 100000000

                        history.append({
                            'date': date_str,
                            'total_flow': round(net_flow, 2),
                            'inflow': max(0, round(net_flow, 2)),
                            'outflow': min(0, round(net_flow, 2))
                        })
                    except Exception as e:
                        logger.debug(f"å¤„ç†ETFæ•°æ®å¤±è´¥: {e}")
                        continue

            if history:
                self.cache[cache_key] = {'data': history, 'timestamp': time.time()}
                logger.info(f"âœ… è·å–ETFèµ„é‡‘æµ{len(history)}å¤©å†å²æ•°æ®ï¼ˆä¸œæ–¹è´¢å¯ŒçœŸå®æ•°æ®ï¼‰")
            else:
                logger.warning("ETFèµ„é‡‘æµæ•°æ®ä¸ºç©ºï¼Œç”Ÿæˆå ä½æ•°æ®")
                # ç”Ÿæˆå ä½æ•°æ®
                for i in range(days):
                    date = datetime.now() - timedelta(days=i)
                    history.append({
                        'date': date.strftime('%Y-%m-%d'),
                        'total_flow': 0.0,
                        'inflow': 0,
                        'outflow': 0
                    })

            return history

        except Exception as e:
            logger.error(f"è·å–ETFèµ„é‡‘æµå†å²æ•°æ®å¤±è´¥: {e}")
            # è¿”å›å ä½æ•°æ®
            history = []
            for i in range(days):
                date = datetime.now() - timedelta(days=i)
                history.append({
                    'date': date.strftime('%Y-%m-%d'),
                    'total_flow': 0.0,
                    'inflow': 0,
                    'outflow': 0
                })
            return history

    def get_main_force_flow_history(self, days: int = 28) -> List[Dict]:
        """
        è·å–ä¸»åŠ›èµ„é‡‘æµå‘å†å²æ•°æ®ï¼ˆä½¿ç”¨ä¸œæ–¹è´¢å¯ŒChoice APIï¼‰

        Args:
            days: è·å–å¤©æ•°

        Returns:
            å†å²æ•°æ®åˆ—è¡¨
        """
        cache_key = f"main_force_history_{days}"
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]['data']

        try:
            # ä½¿ç”¨ä¸œæ–¹è´¢å¯Œä¸»åŠ›èµ„é‡‘æµAPI
            url = "http://datacenter-web.eastmoney.com/api/data/v1/get"
            params = {
                'reportName': 'RPT_MAIN_FORCE_FLOW',  # ä¸»åŠ›èµ„é‡‘æµæŠ¥è¡¨
                'columns': 'ALL',
                'pageSize': str(days),
                'sortColumns': 'TRADE_DATE',
                'sortTypes': '-1',
                'source': 'WEB',
                'client': 'WEB',
                'filter': '(TRADE_DATE>="2020-01-01")'
            }

            response = self.session.get(url, params=params, timeout=10)
            data = response.json()

            history = []
            if data and 'result' in data and data['result'] and 'data' in data['result']:
                items = data['result']['data']

                for item in items[:days]:
                    try:
                        date_str = str(item.get('TRADE_DATE', ''))[:10]
                        # ä¸»åŠ›å‡€æµå…¥ï¼ˆå•ä½ï¼šå…ƒï¼Œè½¬ä¸ºäº¿ï¼‰
                        main_net = float(item.get('MAIN_FORCE_NET', 0)) / 100000000
                        super_large = float(item.get('SUPER_LARGE_NET', 0)) / 100000000
                        large = float(item.get('LARGE_NET', 0)) / 100000000
                        medium = float(item.get('MEDIUM_NET', 0)) / 100000000
                        small = float(item.get('SMALL_NET', 0)) / 100000000

                        history.append({
                            'date': date_str,
                            'total_flow': round(main_net, 2),
                            'super_large': round(super_large, 2),
                            'large': round(large, 2),
                            'medium': round(medium, 2),
                            'small': round(small, 2)
                        })
                    except Exception as e:
                        logger.debug(f"å¤„ç†ä¸»åŠ›èµ„é‡‘æ•°æ®å¤±è´¥: {e}")
                        continue

            if history:
                self.cache[cache_key] = {'data': history, 'timestamp': time.time()}
                logger.info(f"âœ… è·å–ä¸»åŠ›èµ„é‡‘{len(history)}å¤©å†å²æ•°æ®ï¼ˆä¸œæ–¹è´¢å¯ŒçœŸå®æ•°æ®ï¼‰")
            else:
                logger.warning("ä¸»åŠ›èµ„é‡‘æ•°æ®ä¸ºç©ºï¼Œç”Ÿæˆå ä½æ•°æ®")
                # ç”Ÿæˆå ä½æ•°æ®
                for i in range(days):
                    date = datetime.now() - timedelta(days=i)
                    history.append({
                        'date': date.strftime('%Y-%m-%d'),
                        'total_flow': 0.0,
                        'super_large': 0.0,
                        'large': 0.0,
                        'medium': 0.0,
                        'small': 0.0
                    })

            return history

        except Exception as e:
            logger.error(f"è·å–ä¸»åŠ›èµ„é‡‘å†å²æ•°æ®å¤±è´¥: {e}")
            # è¿”å›å ä½æ•°æ®
            history = []
            for i in range(days):
                date = datetime.now() - timedelta(days=i)
                history.append({
                    'date': date.strftime('%Y-%m-%d'),
                    'total_flow': 0.0,
                    'super_large': 0.0,
                    'large': 0.0,
                    'medium': 0.0,
                    'small': 0.0
                })
            return history

    def calculate_period_flow(self, history: List[Dict], periods: List[int] = [1, 3, 7, 14, 28]) -> Dict:
        """
        è®¡ç®—å¤šå‘¨æœŸèµ„é‡‘æµå…¥æµå‡ºç»Ÿè®¡

        Args:
            history: å†å²æ•°æ®åˆ—è¡¨
            periods: ç»Ÿè®¡å‘¨æœŸåˆ—è¡¨ï¼ˆå¤©æ•°ï¼‰

        Returns:
            å¤šå‘¨æœŸç»Ÿè®¡ç»“æœ
        """
        if not history:
            return {}

        result = {}
        for period in periods:
            period_data = history[:min(period, len(history))]

            total_inflow = sum(max(0, d.get('total_flow', 0)) for d in period_data)
            total_outflow = sum(min(0, d.get('total_flow', 0)) for d in period_data)
            net_flow = sum(d.get('total_flow', 0) for d in period_data)

            result[f'{period}d'] = {
                'period': period,
                'inflow': round(total_inflow, 2),
                'outflow': round(abs(total_outflow), 2),
                'net_flow': round(net_flow, 2),
                'avg_daily_flow': round(net_flow / period if period > 0 else 0, 2),
                'flow_ratio': round((total_inflow / abs(total_outflow) if total_outflow != 0 else 0), 2)
            }

        return result

    def get_comprehensive_timing_data(self) -> Dict:
        """
        è·å–ç»¼åˆæ‹©æ—¶æ•°æ®

        Returns:
            åŒ…å«åŒ—å‘èµ„é‡‘ã€ETFèµ„é‡‘ã€ä¸»åŠ›èµ„é‡‘çš„å®Œæ•´æ‹©æ—¶æ•°æ®
        """
        logger.info("ğŸš€ å¼€å§‹è·å–ç»¼åˆæ‹©æ—¶æ•°æ®...")

        # è·å–å„ç±»èµ„é‡‘çš„å†å²æ•°æ®
        north_history = self.get_north_bound_flow_history(days=30)
        etf_history = self.get_etf_flow_history(days=30)
        main_force_history = self.get_main_force_flow_history(days=30)

        # è®¡ç®—å¤šå‘¨æœŸç»Ÿè®¡
        periods = [1, 3, 7, 14, 28]

        result = {
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'north_bound': {
                'latest': north_history[0] if north_history else {},
                'periods': self.calculate_period_flow(north_history, periods),
                'history': north_history[:7]  # æœ€è¿‘7å¤©
            },
            'etf_flow': {
                'latest': etf_history[0] if etf_history else {},
                'periods': self.calculate_period_flow(etf_history, periods),
                'history': etf_history[:7]
            },
            'main_force': {
                'latest': main_force_history[0] if main_force_history else {},
                'periods': self.calculate_period_flow(main_force_history, periods),
                'history': main_force_history[:7]
            },
            'timing_signal': self._generate_timing_signal(
                north_history, etf_history, main_force_history
            )
        }

        logger.info("âœ… ç»¼åˆæ‹©æ—¶æ•°æ®è·å–å®Œæˆ")
        return result

    def _generate_timing_signal(self, north_history: List[Dict],
                                etf_history: List[Dict],
                                main_force_history: List[Dict]) -> Dict:
        """
        ç”Ÿæˆæ‹©æ—¶ä¿¡å·

        Returns:
            æ‹©æ—¶ä¿¡å·å’Œå»ºè®®
        """
        signals = []
        score = 0

        # åŒ—å‘èµ„é‡‘ä¿¡å·
        if north_history:
            north_3d = sum(d.get('total_flow', 0) for d in north_history[:3])
            if north_3d > 50:
                signals.append("åŒ—å‘èµ„é‡‘3æ—¥å‡€æµå…¥è¶…50äº¿ï¼Œå¸‚åœºæƒ…ç»ªç§¯æ")
                score += 2
            elif north_3d < -50:
                signals.append("åŒ—å‘èµ„é‡‘3æ—¥å‡€æµå‡ºè¶…50äº¿ï¼Œéœ€è°¨æ…")
                score -= 2

        # ETFèµ„é‡‘ä¿¡å·
        if etf_history:
            etf_7d = sum(d.get('total_flow', 0) for d in etf_history[:7])
            if etf_7d > 20:
                signals.append("ETFèµ„é‡‘7æ—¥æŒç»­æµå…¥ï¼Œæœºæ„çœ‹å¥½åå¸‚")
                score += 1
            elif etf_7d < -20:
                signals.append("ETFèµ„é‡‘7æ—¥æŒç»­æµå‡ºï¼Œæœºæ„å‡ä»“")
                score -= 1

        # ä¸»åŠ›èµ„é‡‘ä¿¡å·
        if main_force_history:
            main_1d = main_force_history[0].get('total_flow', 0) if main_force_history else 0
            if main_1d > 100:
                signals.append("ä¸»åŠ›èµ„é‡‘ä»Šæ—¥å¤§å¹…æµå…¥ï¼ŒçŸ­æœŸçœ‹å¤š")
                score += 1
            elif main_1d < -100:
                signals.append("ä¸»åŠ›èµ„é‡‘ä»Šæ—¥å¤§å¹…æµå‡ºï¼ŒçŸ­æœŸçœ‹ç©º")
                score -= 1

        # ç»¼åˆè¯„åˆ†
        if score >= 3:
            suggestion = "å¼ºçƒˆçœ‹å¤š"
            level = "strong_bullish"
        elif score >= 1:
            suggestion = "åå¤š"
            level = "bullish"
        elif score <= -3:
            suggestion = "å¼ºçƒˆçœ‹ç©º"
            level = "strong_bearish"
        elif score <= -1:
            suggestion = "åç©º"
            level = "bearish"
        else:
            suggestion = "ä¸­æ€§è§‚æœ›"
            level = "neutral"

        return {
            'score': score,
            'level': level,
            'suggestion': suggestion,
            'signals': signals,
            'timestamp': datetime.now().isoformat()
        }

    def compute_index_trend(self, index_code: str = '000300', above_days: int = 3, ma_short: int = 20, ma_long: int = 30) -> Dict[str, Any]:
        """åŸºäºæ—¥Kåˆ¤æ–­æŒ‡æ•°æ˜¯å¦ç«™ç¨³MA20/MA30å¹¶å‘ä¸Šï¼ˆä½¿ç”¨ä¸œæ–¹è´¢å¯ŒKçº¿ï¼‰

        Returns:
            {
              'index_code','index_name','latest_close','ma20','ma30',
              'above_ma20','above_ma30','stand_above_days','ma20_slope','ma30_slope','is_uptrend'
            }
        """
        try:
            klines = eastmoney_service.get_kline_data(index_code, period='101', count=max(above_days + ma_long + 5, 60))
            if not klines:
                return {
                    'index_code': index_code,
                    'index_name': 'æŒ‡æ•°',
                    'error': 'no_kline',
                    'is_uptrend': False
                }

            closes = [k['close'] for k in klines]
            name = klines[-1].get('name', '') if 'name' in klines[-1] else ''

            def moving_avg(arr, n):
                if len(arr) < n:
                    return []
                return [sum(arr[i-n:i]) / n for i in range(n, len(arr)+1)]

            ma20_series = moving_avg(closes, ma_short)
            ma30_series = moving_avg(closes, ma_long)
            if not ma20_series or not ma30_series:
                return {
                    'index_code': index_code,
                    'index_name': name or 'æŒ‡æ•°',
                    'error': 'insufficient_data',
                    'is_uptrend': False
                }

            latest_close = closes[-1]
            latest_ma20 = ma20_series[-1]
            latest_ma30 = ma30_series[-1]

            above_ma20 = latest_close > latest_ma20
            above_ma30 = latest_close > latest_ma30
            stand_days = 0
            for i in range(1, above_days+1):
                c = closes[-i]
                m20 = ma20_series[-i]
                m30 = ma30_series[-i]
                if c > m20 and c > m30:
                    stand_days += 1
            ma20_slope = ma20_series[-1] - ma20_series[-2] if len(ma20_series) >= 2 else 0
            ma30_slope = ma30_series[-1] - ma30_series[-2] if len(ma30_series) >= 2 else 0

            is_uptrend = (above_ma20 and above_ma30 and stand_days >= above_days and
                          latest_ma20 > latest_ma30 and ma20_slope > 0)

            return {
                'index_code': index_code,
                'index_name': name or index_code,
                'latest_close': round(latest_close, 2),
                'ma20': round(latest_ma20, 2),
                'ma30': round(latest_ma30, 2),
                'above_ma20': above_ma20,
                'above_ma30': above_ma30,
                'stand_above_days': stand_days,
                'ma20_slope': round(ma20_slope, 4),
                'ma30_slope': round(ma30_slope, 4),
                'is_uptrend': bool(is_uptrend)
            }
        except Exception as e:
            logger.error(f"è®¡ç®—æŒ‡æ•°è¶‹åŠ¿å¤±è´¥: {e}")
            return {
                'index_code': index_code,
                'index_name': 'æŒ‡æ•°',
                'error': str(e),
                'is_uptrend': False
            }

    def compute_emotion_phase(self) -> Dict[str, Any]:
        """æƒ…ç»ªåˆ†æœŸç²—ç•¥åˆ¤åˆ«ï¼ˆåŸºäºå…¨å¸‚åœºæ¶¨è·Œä¸æ¢æ‰‹ç‡åˆ†å¸ƒï¼Œæ¥æºï¼šä¸œæ–¹è´¢å¯Œè‚¡ç¥¨åˆ—è¡¨ï¼‰

        è§„åˆ™è¿‘ä¼¼ï¼š
          - å†°ç‚¹ï¼šä¸Šæ¶¨å æ¯”<0.3 ä¸” é«˜æ¢æ‰‹ä¸‹è·Œå æ¯”é«˜
          - ä¿®å¤ï¼šä¸Šæ¶¨å æ¯”åœ¨0.45~0.65 ä¸” å‡€æµå…¥è¯„åˆ†>=0 æˆ– æŒ‡æ•°æ­¢è·Œ
          - åŠ é€Ÿï¼šä¸Šæ¶¨å æ¯”>0.65 ä¸” å¼ºåŠ¿ä¸Šæ¶¨å æ¯”é«˜
          - é€€æ½®ï¼šä¸Šæ¶¨å æ¯”<0.45 ä¸” è¿‘æœŸèµ„é‡‘è¯„åˆ†<=-1
        """
        try:
            stocks = eastmoney_service.get_stock_list(market='all')
            total = len(stocks)
            if total == 0:
                return {'phase': 'æœªçŸ¥', 'basis': ['å¸‚åœºåˆ—è¡¨ä¸ºç©º'], 'metrics': {}}

            ups = sum(1 for s in stocks if s.get('change_pct', 0) > 0)
            strong_up = sum(1 for s in stocks if s.get('change_pct', 0) >= 0.02)
            high_to_down = sum(1 for s in stocks if s.get('change_pct', 0) < 0 and (s.get('turnover_rate', 0) or 0) > 0.03)

            up_ratio = ups / total
            strong_up_ratio = strong_up / total
            high_to_down_ratio = high_to_down / total

            basis = [
                f"ä¸Šæ¶¨å æ¯” {up_ratio:.2%}",
                f"å¼ºåŠ¿ä¸Šæ¶¨å æ¯” {strong_up_ratio:.2%}",
                f"é«˜æ¢æ‰‹ä¸‹è·Œå æ¯” {high_to_down_ratio:.2%}"
            ]

            comp = self.get_comprehensive_timing_data()
            score = comp.get('timing_signal', {}).get('score', 0)

            if up_ratio < 0.30 and high_to_down_ratio > 0.10:
                phase = 'å†°ç‚¹'
            elif up_ratio > 0.65 and strong_up_ratio > 0.25:
                phase = 'åŠ é€Ÿ'
            elif up_ratio < 0.45 and score <= -1:
                phase = 'é€€æ½®'
            else:
                phase = 'ä¿®å¤'

            return {
                'phase': phase,
                'basis': basis,
                'metrics': {
                    'total': total,
                    'up_ratio': round(up_ratio, 4),
                    'strong_up_ratio': round(strong_up_ratio, 4),
                    'high_to_down_ratio': round(high_to_down_ratio, 4),
                    'score': score
                }
            }
        except Exception as e:
            logger.error(f"æƒ…ç»ªåˆ†æœŸè®¡ç®—å¤±è´¥: {e}")
            return {'phase': 'æœªçŸ¥', 'basis': [f'é”™è¯¯: {e}'], 'metrics': {}}

    def get_timing_overview(self, index_code: str = '000300') -> Dict[str, Any]:
        """æ‹©æ—¶åŒºæ€»è§ˆï¼šè¶‹åŠ¿ + èµ„é‡‘ + æƒ…ç»ª"""
        trend = self.compute_index_trend(index_code=index_code)
        comp = self.get_comprehensive_timing_data()
        emotion = self.compute_emotion_phase()

        nb_net3 = sum(d.get('total_flow', 0) for d in self.get_north_bound_flow_history(days=3))
        etf_net7 = sum(d.get('total_flow', 0) for d in self.get_etf_flow_history(days=7))
        main_1d = (self.get_main_force_flow_history(days=1)[0].get('total_flow', 0)
                   if self.get_main_force_flow_history(days=1) else 0)

        capital_brief = {
            'north_3d': round(nb_net3, 2),
            'etf_7d': round(etf_net7, 2),
            'main_1d': round(main_1d, 2),
            'score': comp.get('timing_signal', {}).get('score', 0),
            'level': comp.get('timing_signal', {}).get('level', 'neutral')
        }

        return {
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'trend': trend,
            'capital': capital_brief,
            'emotion': emotion
        }

    def _is_cache_valid(self, key: str, duration: int = None) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if key not in self.cache:
            return False

        cache_duration = duration if duration else self.cache_duration
        return (time.time() - self.cache[key]['timestamp']) < cache_duration

    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        logger.info("ç¼“å­˜å·²æ¸…ç©º")


# å…¨å±€å®ä¾‹
timing_service = CapitalFlowTimingService()


# æµ‹è¯•å‡½æ•°
def main():
    print("=" * 80)
    print("ğŸ¯ èµ„é‡‘æµå‘æ‹©æ—¶æœåŠ¡æµ‹è¯•")
    print("=" * 80)
    print()

    # è·å–ç»¼åˆæ‹©æ—¶æ•°æ®
    print("[1/1] è·å–ç»¼åˆæ‹©æ—¶æ•°æ®...")
    data = timing_service.get_comprehensive_timing_data()

    print("\n" + "=" * 80)
    print("ğŸ“Š åŒ—å‘èµ„é‡‘")
    print("=" * 80)
    print(f"æœ€æ–°: {data['north_bound']['latest']}")
    print(f"\nå¤šå‘¨æœŸç»Ÿè®¡:")
    for period, stats in data['north_bound']['periods'].items():
        print(f"  {period}: å‡€æµå…¥ {stats['net_flow']}äº¿ (æµå…¥{stats['inflow']}äº¿ / æµå‡º{stats['outflow']}äº¿)")

    print("\n" + "=" * 80)
    print("ğŸ“ˆ ETFèµ„é‡‘æµ")
    print("=" * 80)
    print(f"æœ€æ–°: {data['etf_flow']['latest']}")
    print(f"\nå¤šå‘¨æœŸç»Ÿè®¡:")
    for period, stats in data['etf_flow']['periods'].items():
        print(f"  {period}: å‡€æµå…¥ {stats['net_flow']}äº¿")

    print("\n" + "=" * 80)
    print("ğŸ›ï¸ ä¸»åŠ›èµ„é‡‘")
    print("=" * 80)
    print(f"æœ€æ–°: {data['main_force']['latest']}")
    print(f"\nå¤šå‘¨æœŸç»Ÿè®¡:")
    for period, stats in data['main_force']['periods'].items():
        print(f"  {period}: å‡€æµå…¥ {stats['net_flow']}äº¿")

    print("\n" + "=" * 80)
    print("ğŸ¯ æ‹©æ—¶ä¿¡å·")
    print("=" * 80)
    signal = data['timing_signal']
    print(f"ç»¼åˆè¯„åˆ†: {signal['score']}")
    print(f"ä¿¡å·çº§åˆ«: {signal['level']}")
    print(f"æŠ•èµ„å»ºè®®: {signal['suggestion']}")
    print(f"\nå…·ä½“ä¿¡å·:")
    for s in signal['signals']:
        print(f"  â€¢ {s}")

    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
å¿«é€Ÿæ•°æ®ä¸‹è½½å™¨ - ä½¿ç”¨è…¾è®¯è´¢ç»API
"""

import requests
import json
import concurrent.futures
import time
from datetime import datetime, timedelta
import glob
from get_daily_price import all_hs300_symbols

def get_stock_data_qq(symbol):
    """ä½¿ç”¨è…¾è®¯è´¢ç»APIå¿«é€Ÿè·å–è‚¡ç¥¨æ•°æ®"""
    try:
        # è…¾è®¯è´¢ç»API - é€Ÿåº¦æ›´å¿«
        market_prefix = "sz" if symbol.startswith(('000', '002', '300')) else "sh"
        url = f"http://qt.gtimg.cn/q={market_prefix}{symbol}"
        
        response = requests.get(url, timeout=5)
        if response.status_code != 200:
            return None
            
        # è§£ææ•°æ®
        data_str = response.text.strip()
        if not data_str:
            return None
            
        # ç®€å•çš„æ•°æ®è§£æ
        parts = data_str.split('~')
        if len(parts) < 50:  # è…¾è®¯APIè¿”å›çº¦50ä¸ªå­—æ®µ
            return None
            
        # æ„é€ ä¸åŸæ ¼å¼å…¼å®¹çš„æ•°æ®
        stock_data = {
            "Meta Data": {
                "1. Information": "Daily Prices (open, high, low, close) and Volumes",
                "2. Symbol": symbol,
                "3. Last Refreshed": datetime.now().strftime('%Y-%m-%d'),
                "4. Output Size": "Compact",
                "5. Time Zone": "Asia/Shanghai"
            },
            "Time Series (Daily)": {
                datetime.now().strftime('%Y-%m-%d'): {
                    "1. buy price": parts[5],  # ä»Šå¼€
                    "2. high": parts[33],      # æœ€é«˜
                    "3. low": parts[34],       # æœ€ä½
                    "4. sell price": parts[3], # ç°ä»·
                    "5. volume": parts[6]      # æˆäº¤é‡
                }
            }
        }
        
        return stock_data
        
    except Exception as e:
        print(f"è·å– {symbol} å¤±è´¥: {e}")
        return None

def save_stock_data(symbol, data):
    """ä¿å­˜è‚¡ç¥¨æ•°æ®"""
    if not data:
        return False
        
    try:
        filename = f'daily_prices_{symbol}.json'
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except:
        return False

def download_batch_fast(symbols, max_workers=10):
    """å¹¶å‘å¿«é€Ÿä¸‹è½½"""
    print(f"ğŸš€ å¿«é€Ÿä¸‹è½½ {len(symbols)} åªè‚¡ç¥¨")
    
    success_count = 0
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_symbol = {
            executor.submit(get_stock_data_qq, symbol): symbol 
            for symbol in symbols
        }
        
        # å¤„ç†ç»“æœ
        for future in concurrent.futures.as_completed(future_to_symbol):
            symbol = future_to_symbol[future]
            try:
                data = future.result()
                if data and save_stock_data(symbol, data):
                    success_count += 1
                    print(f"âœ… {symbol} ({success_count}/{len(symbols)})")
                else:
                    print(f"âŒ {symbol}")
            except Exception as e:
                print(f"ğŸ’¥ {symbol}: {e}")
    
    return success_count

def fast_download_main():
    """å¿«é€Ÿä¸‹è½½ä¸»ç¨‹åº"""
    print("âš¡ å¿«é€ŸAè‚¡æ•°æ®ä¸‹è½½å™¨")
    print("=" * 40)
    
    # è·å–éœ€è¦ä¸‹è½½çš„è‚¡ç¥¨
    existing_files = glob.glob('./daily_prices_[0-9]*.json')
    existing_symbols = [f.split('_')[-1].replace('.json', '') for f in existing_files]
    remaining = [s for s in all_hs300_symbols if s not in existing_symbols]
    
    print(f"ğŸ“Š å½“å‰å·²æœ‰: {len(existing_symbols)} åª")
    print(f"ğŸ“¦ éœ€è¦ä¸‹è½½: {len(remaining)} åª")
    
    if not remaining:
        print("ğŸ‰ æ‰€æœ‰æ•°æ®å·²å®Œæˆï¼")
        return
    
    # åˆ†æ‰¹ä¸‹è½½ï¼Œæ¯æ‰¹50åª
    batch_size = 50
    total_success = 0
    
    for i in range(0, len(remaining), batch_size):
        batch = remaining[i:i+batch_size]
        batch_num = i // batch_size + 1
        total_batches = (len(remaining) + batch_size - 1) // batch_size
        
        print(f"\nğŸ”„ æ‰¹æ¬¡ {batch_num}/{total_batches}")
        start_time = time.time()
        
        success = download_batch_fast(batch, max_workers=20)
        total_success += success
        
        elapsed = time.time() - start_time
        print(f"â±ï¸ æ‰¹æ¬¡ç”¨æ—¶: {elapsed:.1f}s")
        print(f"ğŸ“ˆ ç´¯è®¡æˆåŠŸ: {len(existing_symbols) + total_success}/{len(all_hs300_symbols)}")
        
        # æ‰¹æ¬¡é—´çŸ­æš‚ä¼‘æ¯
        if i + batch_size < len(remaining):
            time.sleep(2)
    
    print(f"\nğŸ‰ å¿«é€Ÿä¸‹è½½å®Œæˆï¼")
    print(f"âœ… æ–°å¢: {total_success} åªè‚¡ç¥¨")

if __name__ == "__main__":
    import os
    os.chdir('/Users/aaron/AI-Trader/data')
    fast_download_main()